from django.shortcuts import render
from django.views import View
from django.views.generic import CreateView
from django.http import JsonResponse
from django.core.serializers import serialize
from django.http import HttpResponse
from django.utils.decorators import method_decorator  
from django.views.decorators.csrf import csrf_exempt 
from django.utils import timezone
from datetime import datetime,timedelta
from .models import *
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import pandas as pd
import numpy as np
from django.conf import settings
import time
import pickle
import os
import joblib

def home(request):
    return render(request, 'index.html')

class JournalView(View):
    def get(self, request, *args, **kwargs):
        return render(request, 'journal.html')

class RiskDashboardView(View):
    def get(self, request, *args, **kwargs):
        return render(request, "risk-dashboard.html")

class SituationView(View):
    def get(self, request, *args, **kwargs):
        return render(request, "situation.html")
    
class HouseAlertsView(View):

    def get(self, request, *args, **kwargs):
        if request.GET.get("house_id") is None:
            qs = HouseAlerts.objects.all()
            data = serialize("json", qs)
            return HttpResponse(data, content_type="application/json", status=200)
        qs = HouseAlerts.objects.filter(house_id=request.GET.get("house_id")).order_by('-date_time')[0]
        data = serialize("json", [qs])
        return HttpResponse(data, content_type="application/json", status=200)

class AlertsView(View):

    def get(self, request, *args, **kwargs):
        if request.GET.get("alert_id") is None:
            qs = Alerts.objects.all()
            data = serialize("json", qs)
            return HttpResponse(data, content_type="application/json", status=200)
        qs = Alerts.objects.filter(id=request.GET.get("alert_id")).order_by('-date_time')[0]
        data = serialize("json", [qs])
        return HttpResponse(data, content_type="application/json", status=200)
    
@method_decorator(csrf_exempt, name='dispatch')
class DetectorDataCreateView(CreateView):
    model = DetectorData
    template_name = "flatpages/detector_data.html"
    context_object_name = "detector_data"
    fields = '__all__'

    def post(self, request, *args, **kwargs):
        if request.POST.get("detector_id") is None:
            return HttpResponse("Bad request", status=400)
        detector_id = request.POST.get("detector_id")
        timestamp = request.POST.get("timestamp") or timezone.now()
        value = request.POST.get("value")
        DetectorData.objects.create(detector_id_id=detector_id, timestamp=timestamp, value=value)
        return HttpResponse("Success", status=200)
    
class DetectorDataView(View):

    def get(self, request, *args, **kwargs):
        if request.GET.get("detector_id") is None:
            qs = DetectorData.objects.all()
            data = serialize("json", qs)
            return HttpResponse(data, content_type="application/json", status=200)
        now = timezone.now()
        if request.GET.get("range") is None:
            qs = DetectorData.objects.filter(detector_id=request.GET.get("detector_id")).order_by('-timestamp')
        elif request.GET.get("range") == "day":
            qs = DetectorData.objects.filter(detector_id=request.GET.get("detector_id"), timestamp__day=now.day).order_by('-timestamp')
        elif request.GET.get("range") == "week":
            qs = DetectorData.objects.filter(detector_id=request.GET.get("detector_id"), timestamp__date__gte=(now - timedelta(days=7)).date()).order_by('-timestamp')
        elif request.GET.get("range") == "month":
            qs = DetectorData.objects.filter(detector_id=request.GET.get("detector_id"), timestamp__date__gte=(now - timedelta(days=30)).date()).order_by('-timestamp')
        elif request.GET.get("range") == "last":
            qs = DetectorData.objects.filter(detector_id=request.GET.get("detector_id")).order_by('-timestamp').first()
            qs = [qs]
        data = serialize("json", qs)
        return HttpResponse(data, content_type="application/json", status=200)
    
class DetectorView(View):
    def get(self, request, *args, **kwargs):
        if request.GET.get("detector_id") is None:
            qs = Detector.objects.all()
            data = serialize("json", qs)
            return HttpResponse(data, content_type="application/json", status=200)
        qs = Detector.objects.get(id=request.GET.get("detector_id"))
        data = serialize("json", [qs])
        return HttpResponse(data, content_type="application/json", status=200)

@method_decorator(csrf_exempt, name='dispatch')
class StateLabelCreateView(CreateView):
    model = StateLabel
    template_name = "flatpages/state_label.html"
    context_object_name = "state_label"
    fields = '__all__'

    def post(self, request, *args, **kwargs):
        if request.POST.get("house_id") is None or request.POST.get("state") is None:
            return HttpResponse("Bad request", status=400)
        house_id = request.POST.get("house_id")
        timestamp = request.POST.get("timestamp") or timezone.now()
        state = request.POST.get("state")
        name = request.POST.get("name") or ""
        description = request.POST.get("description") or ""

        StateLabel.objects.create(house_id_id=house_id, timestamp=timestamp, state=state, name=name, description=description)
        return HttpResponse("Success", status=200)

class HouseView(View):
    def get(self, request, *args, **kwargs):
        if request.GET.get("house_id") is None:
            qs = House.objects.all()
            data = serialize("json", qs)
            return HttpResponse(data, content_type="application/json", status=200)
        qs = House.objects.get(id=request.GET.get("house_id"))
        data = serialize("json", [qs])
        return HttpResponse(data, content_type="application/json", status=200)

class RealDataRetrainer:
    def __init__(self, sequence_length=12):
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_columns = None
        self.execution_time = 0
        self.test_loss = 0
        self.test_accuracy = 0

    def _round_flow_value(self, value):
        """–û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Ä–∞—Å—Ö–æ–¥–æ–≤ –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π"""
        return round(value, 2) if pd.notnull(value) else value

    def _round_temp_value(self, value):
        """–û–∫—Ä—É–≥–ª–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–æ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª"""
        return round(value) if pd.notnull(value) else value

    def load_trained_model(self, model_path, metadata_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = tf.keras.models.load_model(model_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open(metadata_path, 'rb') as f:
            metadata = pickle.load(f)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.scaler = metadata['scaler']
        self.label_encoder = metadata['label_encoder']
        self.feature_columns = metadata['feature_columns']
        self.sequence_length = metadata['sequence_length']

        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {model_path}")

    def create_features(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏"""
        features = df.copy()

        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏
        features['imbalance'] = (features['flow_xvs'] - features['flow_gvs']).apply(self._round_flow_value)
        features['imbalance_ratio'] = (1 - (features['flow_gvs'] / features['flow_xvs'])).apply(self._round_flow_value)
        features['temp_difference'] = (features['temp_supply'] - features['temp_return']).apply(self._round_temp_value)
        features['hour'] = features['timestamp'].dt.hour

        # –†–∞–∑–Ω–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏
        for col in ['flow_xvs', 'flow_gvs', 'imbalance']:
            for window in [1, 3, 12]:
                features[f'{col}_diff_{window}h'] = (features[col] - features[col].shift(window)).apply(self._round_flow_value)

        for col in ['temp_supply', 'temp_return']:
            for window in [1, 3, 12]:
                features[f'{col}_diff_{window}h'] = (features[col] - features[col].shift(window)).apply(self._round_temp_value)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏
        for col in ['flow_xvs', 'flow_gvs', 'imbalance']:
            for window in [3, 12]:
                features[f'{col}_mean_{window}h'] = features[col].rolling(window=window).mean().apply(self._round_flow_value)
                features[f'{col}_std_{window}h'] = features[col].rolling(window=window).std().apply(self._round_flow_value)

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        features = features.bfill().ffill().dropna()

        print(f"–°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len([col for col in features.columns if col not in ['timestamp', 'label']])}")
        return features

    def prepare_sequences(self, features_df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        numeric_columns = [col for col in features_df.columns
                          if col not in ['timestamp', 'label']
                          and features_df[col].dtype in ['float64', 'int64']]

        self.feature_columns = numeric_columns
        X = features_df[numeric_columns].values
        y = features_df['label'].values

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        X_scaled = self.scaler.fit_transform(X)

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        X_seq, y_seq = [], []
        step = 2
        for i in range(0, len(X_scaled) - self.sequence_length, step):
            X_seq.append(X_scaled[i:(i + self.sequence_length)])
            y_seq.append(y[i + self.sequence_length])

        return np.array(X_seq), np.array(y_seq)

    def build_model(self, n_features, n_classes):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—É)"""
        model = Sequential([
            LSTM(32, return_sequences=True, input_shape=(self.sequence_length, n_features)),
            Dropout(0.3),
            LSTM(16, return_sequences=False),
            Dropout(0.3),
            Dense(16, activation='relu'),
            Dense(n_classes, activation='softmax')
        ])

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        return model

    def retrain_model(self, data, days_back=30, epochs=10):
        start_time = time.time()
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("=== –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ù–ê –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• ===")

        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        data = data

        if len(data) < self.sequence_length:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º {self.sequence_length} –∑–∞–ø–∏—Å–µ–π")

        # 2. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("2. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        features = self.create_features(data)

        # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        print("3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")
        X_seq, y_seq = self.prepare_sequences(features)
        y_encoded = self.label_encoder.fit_transform(y_seq)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X_seq, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

        print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
        print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")
        print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.unique(y_seq, return_counts=True)}")

        # 4. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        n_features = X_train.shape[2]
        n_classes = len(self.label_encoder.classes_)
        self.model = self.build_model(n_features, n_classes)

        early_stop = EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )

        print("4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=64,
            validation_data=(X_test, y_test),
            callbacks=[early_stop],
            verbose=1
        )

        # 5. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        self.test_loss, self.test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {self.test_accuracy:.4f}")
        end_time = time.time()  
        self.execution_time = end_time - start_time
        return history, features

    def save_retrained_model(self, base_path="retrained_models", house_id=None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –¥–∞—Ç–æ–π –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏"""
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ —Å –¥–∞—Ç–æ–π
        current_date = datetime.now().strftime("%Y%m%d_%H%M")
        model_filename = f"anomaly_model_retrained_{current_date}.keras"
        metadata_filename = f"model_metadata_retrained_{current_date}.pkl"

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        info_content = f"""–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:
- –î–∞—Ç–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.feature_columns)}
- –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {self.sequence_length}
- –ö–ª–∞—Å—Å—ã: {list(self.label_encoder.classes_)}
- –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {self.test_accuracy:.4f}
- –¢–µ—Å—Ç–æ–≤—ã–µ –ø–æ—Ç–µ—Ä–∏: {self.test_loss:.4f}
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {self.execution_time:.2f}
"""
      
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.join(settings.MEDIA_ROOT, base_path), exist_ok=True)
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_path = os.path.join(settings.MEDIA_ROOT, f"{base_path}/{model_filename}")
        self.model.save(model_path, overwrite=True)
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata_path = os.path.join(settings.MEDIA_ROOT, f"{base_path}/{metadata_filename}")
        metadata = {
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'feature_columns': self.feature_columns,
            'sequence_length': self.sequence_length,
            'retrain_date': current_date
        }
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        savedmodel = SavedModel.objects.create(
            timestamp=current_date,
            name=model_filename,
            description=info_content,
            model_file=model_path,
            metadata_file=metadata_path,
            accuracy=self.test_accuracy
        )
        house_obj = House.objects.get(id=house_id)
        ModelForHouse.objects.create(house_id=house_obj, model_id=savedmodel, 
                                         name=model_filename, description=info_content, 
                                         timestamp=current_date)
        print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
        return "–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!"


def retrain_model(data, days_back=30, epochs=8, house_id=None):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        retrainer = RealDataRetrainer(sequence_length=12)
        history, features = retrainer.retrain_model(
            data=data,
            days_back=days_back, 
            epochs=epochs,
        )
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        result = retrainer.save_retrained_model(house_id=house_id)
        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏: {e}"

def prepare_data(house, detectors_list, days_back=30):
    data = pd.DataFrame()
    now = timezone.now()
    days_back=30  # –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
    for detector in detectors_list:
        detector_data = pd.DataFrame(DetectorData.objects.filter(detector_id=detector.detector_id, timestamp__date__gte=(now - timedelta(days=days_back)).date()).order_by('-timestamp').values('timestamp','value'))
        detector_data.rename(columns={"value":detector.name}, inplace=True)
        detector_data['timestamp'] = pd.to_datetime(detector_data['timestamp'])
        detector_data = detector_data.set_index('timestamp')
        data = pd.concat([data,detector_data],axis=1)
    labels = pd.DataFrame(StateLabel.objects.filter(house_id=house, timestamp__date__gte=(now - timedelta(days=days_back)).date()).order_by('-timestamp').values('timestamp','state'))
    labels.rename(columns={"state":'label'}, inplace=True)
    labels['timestamp'] = pd.to_datetime(labels['timestamp'])
    labels = labels.set_index('timestamp')
    data = pd.concat([data,labels],axis=1)
    data = data.reset_index()
    return data

def train_model(request): 
    if request.method == 'GET':
        if request.GET.get("house_id") is None:
            return HttpResponse("Bad request", status=400)
        house = request.GET.get("house_id")
        try:
            model = ModelForHouse.objects.get(house_id=house)
        except:
            model = None
        days_back=30
        detectors_list = DetectorsAtHouse.objects.filter(house_id=house)
        if not len(detectors_list):
            return HttpResponse("Bad request. No detectors", status=400)
        data = prepare_data(house, detectors_list, days_back=days_back)
        print(data)
        epochs=8
        result = retrain_model(data, days_back=days_back, epochs=epochs, house_id=house)
        return HttpResponse(f"{result}", status=200)
    
def predict(request):
    if request.method == 'GET':
        if request.GET.get("house_id") is None:
            return HttpResponse("Bad request", status=400)
        house = request.GET.get("house_id")
        try:
            saved_model = ModelForHouse.objects.get(house_id=house)
            model_file_path = saved_model.model_id.model_file.path
            metadata_file_path = saved_model.model_id.metadata_file.path
        except Exception as e:
            return HttpResponse(f"Bad request. {e}", status=400)

        detectors_list = DetectorsAtHouse.objects.filter(house_id=house)
        if not len(detectors_list):
            return HttpResponse("Bad request. No detectors.", status=400)
        data = prepare_data(house, detectors_list)
        predictor = RealDataRetrainer(sequence_length=12)
        predictor.load_trained_model(model_file_path, metadata_file_path)
        features = predictor.create_features(data)
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if len(features) > predictor.sequence_length:
            demo_idx = len(features) - 1
            demo_data = features.iloc[demo_idx-predictor.sequence_length:demo_idx][predictor.feature_columns].values

            prediction = predictor.model.predict(
                demo_data.reshape(1, predictor.sequence_length, -1), verbose=0
            )
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            predicted_class = np.argmax(prediction[0])
            predicted_label_name = predictor.label_encoder.inverse_transform([predicted_class])[0]
            confidence = np.max(prediction[0])
            print(str(data['timestamp'].min()))
            print(str(data['timestamp'].max()))
            print(str(data['timestamp'].max()+timedelta(hours=1)))
            print(f"üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –∞–Ω–æ–º–∞–ª–∏–∏: {predicted_label_name}")
            print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")
            try:
                label = StateLabel.objects.get(house_id=house, timestamp=data['timestamp'].max()+timedelta(hours=1))
                label.state = predicted_label_name
                label.confidence = confidence
                label.confirmed = False
                label.save()
            except:
                StateLabel.objects.create(house_id=house, timestamp=data['timestamp'].max()+timedelta(hours=1), state=predicted_label_name, confidence=confidence)
            return HttpResponse(f"–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {str(data['timestamp'].max()+timedelta(hours=1))}: {predicted_label_name} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})", status=200)
        else:
            return HttpResponse(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. –ù—É–∂–Ω–æ {predictor.sequence_length}, –µ—Å—Ç—å {len(features)}", status=400)
        

def forecast(request):
    if request.method == 'GET':
        if request.GET.get("house_id") is None:
            return HttpResponse("Bad request", status=400)
        house = request.GET.get("house_id")

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    base_path="forecast"
    model_filename =  os.path.join(settings.MEDIA_ROOT, f"{base_path}/{'fast_forecast_model.pkl'}")
    metadata_filename = os.path.join(settings.MEDIA_ROOT, f"{base_path}/{'forecast_metadata.pkl'}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    try:
        model = joblib.load(model_filename)
        metadata = joblib.load(metadata_filename)
        print("–ú–æ–¥–µ–ª—å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {metadata['feature_count']}")
        print(f"–¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {metadata['target_names']}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å, —Å–æ–∑–¥–∞–¥–∏–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        print("–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        from sklearn.ensemble import RandomForestRegressor
        model = RandomForestRegressor()
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–¥–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'feature_names': ['flow_xvs', 'flow_gvs', 'temp_supply', 'temp_return', 'imbalance',
                            'imbalance_ratio', 'temp_difference', 'hour', 'day_of_week',
                            'flow_xvs_mean_3h', 'flow_gvs_mean_3h', 'imbalance_mean_3h',
                            'flow_xvs_diff_1h', 'flow_gvs_diff_1h', 'temp_supply_diff_1h',
                            'temp_return_diff_1h', 'flow_xvs_diff_3h', 'flow_gvs_diff_3h',
                            'temp_supply_diff_3h', 'temp_return_diff_3h'],
            'target_names': ['flow_xvs_168', 'flow_gvs_168', 'temp_supply_168', 'temp_return_168',
                            'flow_xvs_336', 'flow_gvs_336', 'temp_supply_336', 'temp_return_336',
                            'flow_xvs_504', 'flow_gvs_504', 'temp_supply_504', 'temp_return_504'],
            'forecast_horizons': [168, 336, 504]
        }

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    print("\n=== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===")

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–∞–∫–∞—è –∂–µ, –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
    def create_features_simple(df):
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º"""

        df = df.copy()
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp').reset_index(drop=True)

        features = pd.DataFrame()

        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        features['flow_xvs'] = df['flow_xvs']
        features['flow_gvs'] = df['flow_gvs']
        features['temp_supply'] = df['temp_supply']
        features['temp_return'] = df['temp_return']

        # –†–∞—Å—á–µ—Ç–Ω—ã–µ –Ω–µ–≤—è–∑–∫–∏ —Å –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º
        features['imbalance'] = round(features['flow_xvs'] - features['flow_gvs'], 2)
        features['imbalance_ratio'] = round(1 - (features['flow_gvs'] / features['flow_xvs'].replace(0, 0.001)), 2)
        features['temp_difference'] = round(features['temp_supply'] - features['temp_return'], 1)

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features['hour'] = df['timestamp'].dt.hour
        features['day_of_week'] = df['timestamp'].dt.dayofweek

        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (3 —á–∞—Å–∞)
        features['flow_xvs_mean_3h'] = round(df['flow_xvs'].rolling(window=3, min_periods=1).mean(), 2)
        features['flow_gvs_mean_3h'] = round(df['flow_gvs'].rolling(window=3, min_periods=1).mean(), 2)
        features['imbalance_mean_3h'] = round(features['imbalance'].rolling(window=3, min_periods=1).mean(), 2)

        # –†–∞–∑–Ω–æ—Å—Ç–∏ –∑–∞ 1 —á–∞—Å
        features['flow_xvs_diff_1h'] = round(df['flow_xvs'].diff(1), 2)
        features['flow_gvs_diff_1h'] = round(df['flow_gvs'].diff(1), 2)
        features['temp_supply_diff_1h'] = round(df['temp_supply'].diff(1), 1)
        features['temp_return_diff_1h'] = round(df['temp_return'].diff(1), 1)

        # –†–∞–∑–Ω–æ—Å—Ç–∏ –∑–∞ 3 —á–∞—Å–∞
        features['flow_xvs_diff_3h'] = round(df['flow_xvs'].diff(3), 2)
        features['flow_gvs_diff_3h'] = round(df['flow_gvs'].diff(3), 2)
        features['temp_supply_diff_3h'] = round(df['temp_supply'].diff(3), 1)
        features['temp_return_diff_3h'] = round(df['temp_return'].diff(3), 1)

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN
        features = features.fillna(method='bfill').fillna(method='ffill')

        return features

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    detectors_list = DetectorsAtHouse.objects.filter(house_id=house)
    if not len(detectors_list):
        return HttpResponse("Bad request. No detectors.", status=400)
    data = prepare_data(house, detectors_list)
    if not data.empty:
        print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(data)} —Å—Ç—Ä–æ–∫")
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = create_features_simple(data)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
        missing_features = set(metadata['feature_names']) - set(features.columns)
        if missing_features:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
            available_features = [f for f in metadata['feature_names'] if f in features.columns]
            features = features[available_features]
        else:
            features = features[metadata['feature_names']]

        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {features.shape}")
    else:
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        dates = pd.date_range(start=datetime.now() - timedelta(days=30), end=datetime.now(), freq='H')
        demo_data = []
        for date in dates:
            demo_data.append({
                'timestamp': date,
                'flow_xvs': round(np.random.uniform(0.15, 0.25), 2),
                'flow_gvs': round(np.random.uniform(0.14, 0.24), 2),
                'temp_supply': round(np.random.uniform(59.0, 61.0), 1),
                'temp_return': round(np.random.uniform(41.0, 43.0), 1),
                'label': 'normal'
            })
        data = pd.DataFrame(demo_data)
        features = create_features_simple(data)
        features = features[metadata['feature_names']]
        print(f"–î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã: {features.shape}")

    # 3. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
    print("\n=== –í–´–ü–û–õ–ù–ï–ù–ò–ï –ü–†–û–ì–ù–û–ó–ê ===")

    # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
    predictions = model.predict(features)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    pred_df = pd.DataFrame(predictions, columns=metadata['target_names'])

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    pred_df['timestamp'] = data['timestamp'].values
    # 4. –í—ã–≤–æ–¥ –ø–µ—Ä–≤—ã—Ö –ø—è—Ç–∏ —Å—Ç—Ä–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n=== –ü–ï–†–í–´–ï 5 –°–¢–†–û–ö –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ü–†–û–ì–ù–û–ó–ê ===")

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    response_str = ""
    # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫
    for i in range(min(5, len(pred_df))):
        print(f"\n--- –°—Ç—Ä–æ–∫–∞ {i+1} ---")
        print(f"–í—Ä–µ–º—è: {pred_df.iloc[i]['timestamp']}")
        response_str = response_str+f"\n--- –°—Ç—Ä–æ–∫–∞ {i+1} ---\n"+f"–í—Ä–µ–º—è: {pred_df.iloc[i]['timestamp']}\n"
        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –Ω–µ–¥–µ–ª—é (168 —á–∞—Å–æ–≤)
        print("–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –Ω–µ–¥–µ–ª—é:")
        print(f"  flow_xvs: {pred_df.iloc[i]['flow_xvs_168']:.3f}")
        print(f"  flow_gvs: {pred_df.iloc[i]['flow_gvs_168']:.3f}")
        print(f"  temp_supply: {pred_df.iloc[i]['temp_supply_168']:.1f}¬∞C")
        print(f"  temp_return: {pred_df.iloc[i]['temp_return_168']:.1f}¬∞C")
        response_str = response_str+"–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –Ω–µ–¥–µ–ª—é:\n"+f"  flow_xvs: {pred_df.iloc[i]['flow_xvs_168']:.3f}\n"+f"  flow_gvs: {pred_df.iloc[i]['flow_gvs_168']:.3f}\n"+f"  temp_supply: {pred_df.iloc[i]['temp_supply_168']:.1f}¬∞C\n"+f"  temp_return: {pred_df.iloc[i]['temp_return_168']:.1f}¬∞C\n"

        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 2 –Ω–µ–¥–µ–ª–∏ (336 —á–∞—Å–æ–≤)
        print("–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 2 –Ω–µ–¥–µ–ª–∏:")
        print(f"  flow_xvs: {pred_df.iloc[i]['flow_xvs_336']:.3f}")
        print(f"  flow_gvs: {pred_df.iloc[i]['flow_gvs_336']:.3f}")
        print(f"  temp_supply: {pred_df.iloc[i]['temp_supply_336']:.1f}¬∞C")
        print(f"  temp_return: {pred_df.iloc[i]['temp_return_336']:.1f}¬∞C")

        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 3 –Ω–µ–¥–µ–ª–∏ (504 —á–∞—Å–æ–≤)
        print("–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 3 –Ω–µ–¥–µ–ª–∏:")
        print(f"  flow_xvs: {pred_df.iloc[i]['flow_xvs_504']:.3f}")
        print(f"  flow_gvs: {pred_df.iloc[i]['flow_gvs_504']:.3f}")
        print(f"  temp_supply: {pred_df.iloc[i]['temp_supply_504']:.1f}¬∞C")
        print(f"  temp_return: {pred_df.iloc[i]['temp_return_504']:.1f}¬∞C")

    # 5. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print("\n=== –°–í–û–î–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø ===")
    print(f"–í—Å–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {len(pred_df)}")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –≤ –¥–∞–Ω–Ω—ã—Ö: {data['timestamp'].min()} - {data['timestamp'].max()}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n=== –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===")
    # results_filename = 'forecast_results.csv'
    # pred_df.to_csv(results_filename, index=False)
    # print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {results_filename}")
    forecast = pred_df.round(2).sort_values('timestamp',ascending=False).loc[0]
    timestamp = forecast['timestamp']
    forecast['timestamp'] = str(timestamp)[:10] + " " + str(timestamp)[11:]  # –£–±–∏—Ä–∞–µ–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –∏–∑ timestamp
    house_obj = House.objects.get(id=house)
    try:
        forecast_obj = Forecast.objects.get(timestamp=timestamp, house_id=house_obj)
        forecast_obj.forecast = forecast.to_json()
        forecast_obj.save()
    except:
        Forecast.objects.create(timestamp=timestamp, house_id=house_obj, forecast=forecast.to_json())

    return HttpResponse(forecast.to_json(), status=200)
